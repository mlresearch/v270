---
title: Trajectory Improvement and Reward Learning from Comparative Language Feedback
abstract: Learning from human feedback has gained traction in fields like robotics
  and natural language processing in recent years. While prior works mostly rely on
  human feedback in the form of comparisons, language is a preferable modality that
  provides more informative insights into user preferences. In this work, we aim to
  incorporate comparative language feedback to iteratively improve robot trajectories
  and to learn reward functions that encode human preferences. To achieve this goal,
  we learn a shared latent space that integrates trajectory data and language feedback,
  and subsequently leverage the learned latent space to improve trajectories and learn
  human preferences. To the best of our knowledge, we are the first to incorporate
  comparative language feedback into reward learning. Our simulation experiments demonstrate
  the effectiveness of the learned latent space and the success of our learning algorithms.
  We also conduct human subject studies that show our reward learning algorithm achieves
  a 23.9% higher subjective score on average and is 11.3% more time-efficient compared
  to preference-based reward learning, underscoring the superior performance of our
  method. Our website is at https://liralab.usc.edu/comparative-language-feedback/.
section: Poster
openreview: 1tCteNSbFH
software: https://github.com/USC-Lira/language-preference-learning
video: https://youtu.be/0649vsxY_eg?si=L97BBDEK8wNASG9t
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang25e
month: 0
tex_title: Trajectory Improvement and Reward Learning from Comparative Language Feedback
firstpage: 5389
lastpage: 5404
page: 5389-5404
order: 5389
cycles: false
bibtex_author: Yang, Zhaojing and Jun, Miru and Tien, Jeremy and Russell, Stuart and
  Dragan, Anca and Biyik, Erdem
author:
- given: Zhaojing
  family: Yang
- given: Miru
  family: Jun
- given: Jeremy
  family: Tien
- given: Stuart
  family: Russell
- given: Anca
  family: Dragan
- given: Erdem
  family: Biyik
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/yang25e/yang25e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
