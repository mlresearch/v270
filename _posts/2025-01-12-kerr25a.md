---
title: 'Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular
  4D Reconstruction'
abstract: 'Humans can learn to manipulate new objects by simply watching others; providing
  robots with the ability to learn from such demonstrations would enable a natural
  interface specifying new behaviors. This work develops Robot See Robot Do (RSRD),
  a method for imitating articulated object manipulation from a single monocular RGB
  human demonstration given a single static multi- view object scan. We first propose
  4D Differentiable Part Models (4D-DPM), a method for recovering 3D part motion from
  a monocular video with differentiable rendering. This analysis-by-synthesis approach
  uses part-centric feature fields in an iterative optimization which enables the
  use of geometric regularizers to re- cover 3D motions from only a single video.
  Given this 4D reconstruction, the robot replicates object trajectories by planning
  bimanual arm motions that induce the demonstrated object part motion. By representing
  demonstrations as part- centric trajectories, RSRD focuses on replicating the demonstration’s
  intended behavior while considering the robot’s own morphological limits, rather
  than at- tempting to reproduce the hand’s motion. We evaluate 4D-DPM’s 3D tracking
  accuracy on ground truth annotated 3D part trajectories and RSRD’s physical ex-
  ecution performance on 9 objects across 10 trials each on a bimanual YuMi robot.
  Each phase of RSRD achieves an average of 87% success rate, for a total end- to-end
  success rate of 60% across 90 trials. Notably, this is accomplished using only feature
  fields distilled from large pretrained vision models — without any task-specific
  training, fine-tuning, dataset collection, or annotation. Project page: https://robot-see-robot-do.github.io'
section: Oral
openreview: 2LLu3gavF1
software: https://github.com/kerrj/rsrd
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kerr25a
month: 0
tex_title: 'Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular
  4D Reconstruction'
firstpage: 587
lastpage: 603
page: 587-603
order: 587
cycles: false
bibtex_author: Kerr, Justin and Kim, Chung Min and Wu, Mingxuan and Yi, Brent and
  Wang, Qianqian and Goldberg, Ken and Kanazawa, Angjoo
author:
- given: Justin
  family: Kerr
- given: Chung Min
  family: Kim
- given: Mingxuan
  family: Wu
- given: Brent
  family: Yi
- given: Qianqian
  family: Wang
- given: Ken
  family: Goldberg
- given: Angjoo
  family: Kanazawa
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/kerr25a/kerr25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
