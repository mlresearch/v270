---
title: 'Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot
  Collaboration'
abstract: 'We introduce Vocal Sandbox, a framework for enabling seamless human-robot
  collaboration in situated environments. Systems in our framework are characterized
  by their ability to *adapt and continually learn* at multiple levels of abstraction
  from diverse teaching modalities such as spoken dialogue, object keypoints, and
  kinesthetic demonstrations. To enable such adaptation, we design lightweight and
  interpretable learning algorithms that allow users to build an understanding and
  co-adapt to a robot’s capabilities in real-time, as they teach new behaviors. For
  example, after demonstrating a new low-level skill for “tracking around” an object,
  users are provided with trajectory visualizations of the robot’s intended motion
  when asked to track a new object. Similarly, users teach high-level planning behaviors
  through spoken dialogue, using pretrained language models to synthesize behaviors
  such as “packing an object away” as compositions of low-level skills – concepts
  that can be reused and built upon. We evaluate Vocal Sandbox in two settings: collaborative
  gift bag assembly and LEGO stop-motion animation. In the first setting, we run systematic
  ablations and user studies with 8 non-expert participants, highlighting the impact
  of multi-level teaching. Across 23 hours of total robot interaction time, users
  teach 17 new high-level behaviors with an average of 16 novel low-level skills,
  requiring 22.1% less active supervision compared to baselines. Qualitatively, users
  strongly prefer Vocal Sandbox systems due to their ease of use (+31.2%), helpfulness
  (+13.0%), and overall performance (+18.2%). Finally, we pair an experienced system-user
  with a robot to film a stop-motion animation; over two hours of continuous collaboration,
  the user teaches progressively more complex motion skills to produce a 52 second
  (232 frame) movie. Videos & Supplementary Material: https://vocal-sandbox.github.io'
section: Oral
openreview: ypaYtV1CoG
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: grannen25a
month: 0
tex_title: 'Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot
  Collaboration'
firstpage: 1
lastpage: 24
page: 1-24
order: 1
cycles: false
bibtex_author: Grannen, Jennifer and Karamcheti, Siddharth and Mirchandani, Suvir
  and Liang, Percy and Sadigh, Dorsa
author:
- given: Jennifer
  family: Grannen
- given: Siddharth
  family: Karamcheti
- given: Suvir
  family: Mirchandani
- given: Percy
  family: Liang
- given: Dorsa
  family: Sadigh
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/grannen25a/grannen25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
