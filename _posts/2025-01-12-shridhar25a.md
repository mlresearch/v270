---
title: Generative Image as Action Models
abstract: Image-generation diffusion models have been fine-tuned to unlock new capabilities
  such as image-editing and novel view synthesis. Can we similarly unlock image-generation
  models for visuomotor control? We present GENIMA, a behavior-cloning agent that
  fine-tunes Stable Diffusion to “draw joint-actions” as targets on RGB images. These
  images are fed into a controller that maps the visual targets into a sequence of
  joint-positions. We study GENIMA on 25 RLBench and 9 real-world manipulation tasks.
  We find that, by lifting actions into image-space, internet pre-trained diffusion
  models can generate policies that outperform state- of-the-art visuomotor approaches,
  especially in robustness to scene perturbations and generalizing to novel objects.
  Our method is also competitive with 3D agents, despite lacking priors such as depth,
  keypoints, or motion-planners.
section: Poster
openreview: cocHfT7CEs
software: https://github.com/MohitShridhar/genima
video: https://youtu.be/V0xJ833dCcU
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shridhar25a
month: 0
tex_title: Generative Image as Action Models
firstpage: 2429
lastpage: 2455
page: 2429-2455
order: 2429
cycles: false
bibtex_author: Shridhar, Mohit and Lo, Yat Long and James, Stephen
author:
- given: Mohit
  family: Shridhar
- given: Yat Long
  family: Lo
- given: Stephen
  family: James
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/shridhar25a/shridhar25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
