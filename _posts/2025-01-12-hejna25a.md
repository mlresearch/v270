---
title: 'ReMix: Optimizing Data Mixtures for Large Scale Imitation Learning'
abstract: Increasingly large robotics datasets are being collected to train larger
  foundation models in robotics. However, despite the fact that data selection has
  been of utmost importance to scaling in vision and natural language processing (NLP),
  little work in robotics has questioned what data such models should actually be
  trained on. In this work we investigate how to weigh different subsets or “domains”
  of robotics datasets during pre-training to maximize worst-case performance across
  all possible downstream domains using distributionally robust optimization (DRO).
  Unlike in NLP, we find that these methods are hard to apply out of the box due to
  varying action spaces and dynamics across robots. Our method, ReMix, employs early
  stopping and action normalization and discretization to counteract these issues.
  Through extensive experimentation on both the Bridge and OpenX datasets, we demonstrate
  that data curation can have an outsized impact on downstream performance. Specifically,
  domain weights learned by ReMix outperform uniform weights by over 40% on average
  and human-selected weights by over 20% on datasets used to train the RT-X models.
section: Oral
openreview: fIj88Tn3fc
software: https://github.com/jhejna/remix
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hejna25a
month: 0
tex_title: 'ReMix: Optimizing Data Mixtures for Large Scale Imitation Learning'
firstpage: 145
lastpage: 164
page: 145-164
order: 145
cycles: false
bibtex_author: Hejna, Joey and Bhateja, Chethan Anand and Jiang, Yichen and Pertsch,
  Karl and Sadigh, Dorsa
author:
- given: Joey
  family: Hejna
- given: Chethan Anand
  family: Bhateja
- given: Yichen
  family: Jiang
- given: Karl
  family: Pertsch
- given: Dorsa
  family: Sadigh
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/hejna25a/hejna25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
