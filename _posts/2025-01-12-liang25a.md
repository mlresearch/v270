---
title: Environment Curriculum Generation via Large Language Models
abstract: Recent work has demonstrated that a promising strategy for teaching robots
  a wide range of complex skills is by training them on a curriculum of progressively
  more challenging environments. However, developing an effective curriculum of environment
  distributions currently requires significant expertise, which must be repeated for
  every new domain. Our key insight is that environments are often naturally represented
  as code. Thus, we probe whether effective environment curriculum design can be achieved
  and automated via code generation by large language models (LLM). In this paper,
  we introduce Eurekaverse, an unsupervised environment design algorithm that uses
  LLMs to sample progressively more challenging, diverse, and learnable environments
  for skill training. We validate Eurekaverseâ€™s effectiveness in the domain of quadrupedal
  parkour learning, in which a quadruped robot must traverse through a variety of
  obstacle courses. The automatic curriculum designed by Eurekaverse enables gradual
  learning of complex parkour skills in simulation and can successfully transfer to
  the real-world, outperforming manual training courses designed by humans.
section: Oral
openreview: F0rWEID2gb
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liang25a
month: 0
tex_title: Environment Curriculum Generation via Large Language Models
firstpage: 433
lastpage: 454
page: 433-454
order: 433
cycles: false
bibtex_author: Liang, William and Wang, Sam and Wang, Hung-Ju and Bastani, Osbert
  and Jayaraman, Dinesh and Ma, Yecheng Jason
author:
- given: William
  family: Liang
- given: Sam
  family: Wang
- given: Hung-Ju
  family: Wang
- given: Osbert
  family: Bastani
- given: Dinesh
  family: Jayaraman
- given: Yecheng Jason
  family: Ma
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/liang25a/liang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
