---
title: 'A3VLM: Actionable Articulation-Aware Vision Language Model'
abstract: Vision Language Models (VLMs) for robotics have received significant attention
  in recent years. As a VLM can understand robot observations and perform complex
  visual reasoning, it is regarded as a potential universal solution for general robotics
  challenges such as manipulation and navigation. However, previous robotics VLMs
  such as RT-1, RT-2, and ManipLLM have focused on directly learning robot actions.
  Such approaches require collecting a significant amount of robot interaction data,
  which is extremely costly in the real world. Thus, we propose A3VLM, an object-centric,
  actionable, articulation-aware vision language model. A3VLM focuses on the articulation
  structure and action affordances of objects. Its representation is robot-agnostic
  and can be translated into robot actions using simple action primitives. Extensive
  experiments in both simulation benchmarks and real-world settings demonstrate the
  effectiveness and stability of A3VLM.
section: Poster
openreview: lyhS75loxe
software: https://github.com/changhaonan/A3VLM
video: https://youtu.be/Fn4bn6IHRSc?feature=shared
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang25b
month: 0
tex_title: 'A3VLM: Actionable Articulation-Aware Vision Language Model'
firstpage: 1675
lastpage: 1690
page: 1675-1690
order: 1675
cycles: false
bibtex_author: Huang, Siyuan and Chang, Haonan and Liu, Yuhan and Zhu, Yimeng and
  Dong, Hao and Boularias, Abdeslam and Gao, Peng and Li, Hongsheng
author:
- given: Siyuan
  family: Huang
- given: Haonan
  family: Chang
- given: Yuhan
  family: Liu
- given: Yimeng
  family: Zhu
- given: Hao
  family: Dong
- given: Abdeslam
  family: Boularias
- given: Peng
  family: Gao
- given: Hongsheng
  family: Li
date: 2025-01-12
address:
container-title: Proceedings of The 8th Conference on Robot Learning
volume: '270'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v270/main/assets/huang25b/huang25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
